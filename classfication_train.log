2018.01.10 12:30
    batchsize128，四对-[卷积（map30,kernel_zie5,stride1,relu）+池化（max,kernel3,stride2）] 全连接1（50+relu）+全连接2输出，test准确率徘徊在90,可尝试的点（dropout(过拟合)，数据增强，该模型（vgg19，alexnet））  

2018.01.11 09:22 
    直接对训练数据测试发现，训练准确率接近1，出现过拟合现象。

2018.01.11 10:00
    在前两层卷积网络中，增加norm层，在全连接1中增加dropout层，有效改善过拟合现象，准确率徘徊在0.96，上下震荡。收敛特别快。

2018.01.11 11:15
    迭代器改用Adam——发散无法收敛
    迭代器指定SGD——正常收敛

2018.01.11 12:06
    学习率策略inv 基础学习率由0.01改为0.001,收敛变慢，准确率0.94左右

2018.01.11 15:30
    学习率策略改为multistep 效果与inv差不多

2018.01.11 17:20
    对训练数据进行了扩充，将原图像进行了水平翻转，即扩充了两倍。准确率提升到0.97左右
    (后续可尝试点：继续扩充数据，微小平移和旋转。迁移他人训练好的模型。补充工作：比较相同参数不同数据集大小)
	
2018.01.14 18:00
     caffe fine-tuning时需要对最后一层更改名字，再改分类数。
	 alexnet fine-tuning 准确率在0.97左右
	 (明日工作：测试mynet改进,sketch-net,分类测试运行)

